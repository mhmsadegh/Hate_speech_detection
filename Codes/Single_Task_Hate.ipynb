{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Single_Task_Hate1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RF3h2up7WFNj",
        "outputId": "f373f7ab-2286-4ed9-9a65-ce365488addd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig33qJONWRCH",
        "outputId": "726939d0-b5a8-4eec-81c4-3dcd6d6f6bfc"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 5.3 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 35.2 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 16.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 48.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.1.2 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "rMEnzUvwWXCV",
        "outputId": "eba8d3d6-ff8f-4aaa-8673-466188aa132e"
      },
      "source": [
        "import pandas as pd\n",
        "train_data =pd.read_csv(\"/content/drive/MyDrive/FMNLP_HW3/WD/train.csv\")\n",
        "validation =pd.read_csv(\"/content/drive/MyDrive/FMNLP_HW3/WD/dev.csv\")\n",
        "test =pd.read_csv(\"/content/drive/MyDrive/FMNLP_HW3/WD/test.csv\")\n",
        "train_data"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Redemption round ( thank goodness ) and home m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Who are these people LOL mkr</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Oh no no no it's a conspiracy. mkr</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Vicky and Celine kickass I hope they do mkr</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A lot of people would like to put Kat to sudde...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3099</th>\n",
              "      <td>countdown to more companies following suit aft...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3100</th>\n",
              "      <td>So, just to save you all some time, BSD is my ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3101</th>\n",
              "      <td>or so I can direct parents there around xmas t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3102</th>\n",
              "      <td>@User @User I agree 100% with this statement.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3103</th>\n",
              "      <td>Disclaimer: None of these things I'm about to ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3104 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  label\n",
              "0     Redemption round ( thank goodness ) and home m...      0\n",
              "1                         Who are these people LOL mkr       0\n",
              "2                   Oh no no no it's a conspiracy. mkr       0\n",
              "3          Vicky and Celine kickass I hope they do mkr       0\n",
              "4     A lot of people would like to put Kat to sudde...      0\n",
              "...                                                 ...    ...\n",
              "3099  countdown to more companies following suit aft...      0\n",
              "3100  So, just to save you all some time, BSD is my ...      0\n",
              "3101  or so I can direct parents there around xmas t...      0\n",
              "3102     @User @User I agree 100% with this statement.       0\n",
              "3103  Disclaimer: None of these things I'm about to ...      0\n",
              "\n",
              "[3104 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt_ii8naWcxk",
        "outputId": "9b3954a7-02c5-43de-fd89-fceb57b81329"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9VjoIfzWhWj"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "        self.labels = list(df['label'])\n",
        "        self.texts = [tokenizer(text, \n",
        "                               padding='max_length', max_length = 64, truncation=True,\n",
        "                                return_tensors=\"pt\") for text in df['text']]\n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        # Fetch a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        # Fetch a batch of inputs\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_texts, batch_y"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqWfFl0NXZf_"
      },
      "source": [
        "from torch import nn\n",
        "from transformers import BertModel\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout=0.5):\n",
        "\n",
        "        super(BertClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 2)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, input_id, mask):\n",
        "\n",
        "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        final_layer = self.relu(linear_output)\n",
        "\n",
        "        return final_layer"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_hMPBDNiFYX"
      },
      "source": [
        "\n",
        "def tensor_to_onehot(tensor_file):\n",
        "  temp = list()\n",
        "  for i in tensor_file.tolist():\n",
        "    if i ==0:\n",
        "      temp.append([1,0])\n",
        "    else:\n",
        "      temp.append([0,1])\n",
        "\n",
        "  return torch.tensor(temp)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld_j4c1zXtFm",
        "outputId": "9590c196-8bde-4cca-f2d5-52135d3f14e0"
      },
      "source": [
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "\n",
        "def train(model, train_data, val_data, learning_rate, epochs):\n",
        "\n",
        "\n",
        "    train_loss_list = []\n",
        "    val_loss_list =[]\n",
        "    train_acc_list = []\n",
        "    val_acc_list = []\n",
        "    val_f1score_list = []\n",
        "\n",
        "    train, val = Dataset(train_data), Dataset(val_data)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=8, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=8)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss(reduction='sum',pos_weight=torch.tensor(1902/1202))\n",
        "    optimizer = AdamW(model.parameters(), lr= learning_rate)\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "            model = model.cuda()\n",
        "            criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "\n",
        "            total_acc_train = 0\n",
        "            total_loss_train = 0\n",
        "\n",
        "            for train_input, train_label in tqdm(train_dataloader):\n",
        "                \n",
        "                train_label = train_label.to(device)\n",
        "                mask = train_input['attention_mask'].to(device)\n",
        "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask)\n",
        "                # print(\"train label\",train_label,\"\\n\")\n",
        "                # target = torch.nn.functional.one_hot(train_label)\n",
        "                target = tensor_to_onehot(train_label)\n",
        "                # print(\"target\",target,\"\\n outpur\",output)\n",
        "                target = target.to(device)\n",
        "                batch_loss = criterion(output, target.float())\n",
        "                total_loss_train += batch_loss.item()\n",
        "                \n",
        "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
        "                total_acc_train += acc\n",
        "\n",
        "                model.zero_grad()\n",
        "                batch_loss.backward()\n",
        "                optimizer.step()\n",
        "            \n",
        "            total_acc_val = 0\n",
        "            total_loss_val = 0\n",
        "            total_f1score_val = 0 \n",
        "            counter = 0\n",
        "            with torch.no_grad():\n",
        "\n",
        "                for val_input, val_label in val_dataloader:\n",
        "                    counter+=1\n",
        "                    val_label = val_label.to(device)\n",
        "                    mask = val_input['attention_mask'].to(device)\n",
        "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                    output = model(input_id, mask)\n",
        "\n",
        "\n",
        "\n",
        "                    target_val = tensor_to_onehot(val_label)\n",
        "                    target_val = target_val.to(device)\n",
        "                    batch_loss = criterion(output, target_val.float())\n",
        "                    total_loss_val += batch_loss.item()\n",
        "                    \n",
        "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
        "                    total_acc_val += acc\n",
        "                    total_f1score_val += f1_score(val_label.tolist(), output.argmax(dim=1).tolist(), average='macro')\n",
        "            \n",
        "            print(\n",
        "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
        "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
        "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
        "                | Val Accuracy: {total_acc_val / len(val_data): .3f}\\\n",
        "                | Val F1_score:{total_f1score_val/counter : .3f}')\n",
        "            train_loss_list.append(total_loss_train / len(train_data))\n",
        "            val_loss_list.append(total_loss_val / len(val_data))\n",
        "            train_acc_list.append(total_acc_train / len(train_data))\n",
        "            val_acc_list.append(total_acc_val / len(val_data))\n",
        "            val_f1score_list.append(total_f1score_val/counter)\n",
        "\n",
        "    return train_loss_list,val_loss_list,train_acc_list,val_acc_list,val_f1score_list           \n",
        "                  \n",
        "EPOCHS = 8\n",
        "model = BertClassifier()\n",
        "LR = 1e-6\n",
        "# LR = 1e-4\n",
        "              \n",
        "train_loss_list,val_loss_list,train_acc_list,val_acc_list,val_f1score_list=train(model, train_data, validation, LR, EPOCHS)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "100%|██████████| 388/388 [01:27<00:00,  4.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss:  1.657                 | Train Accuracy:  0.620                 | Val Loss:  1.524                 | Val Accuracy:  0.700                | Val F1_score: 0.544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 388/388 [01:27<00:00,  4.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2 | Train Loss:  1.448                 | Train Accuracy:  0.756                 | Val Loss:  1.349                 | Val Accuracy:  0.786                | Val F1_score: 0.645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 388/388 [01:27<00:00,  4.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3 | Train Loss:  1.317                 | Train Accuracy:  0.799                 | Val Loss:  1.261                 | Val Accuracy:  0.795                | Val F1_score: 0.665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 388/388 [01:27<00:00,  4.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 4 | Train Loss:  1.214                 | Train Accuracy:  0.833                 | Val Loss:  1.177                 | Val Accuracy:  0.847                | Val F1_score: 0.726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 388/388 [01:27<00:00,  4.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 5 | Train Loss:  1.133                 | Train Accuracy:  0.862                 | Val Loss:  1.150                 | Val Accuracy:  0.851                | Val F1_score: 0.746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 388/388 [01:27<00:00,  4.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 6 | Train Loss:  1.064                 | Train Accuracy:  0.897                 | Val Loss:  1.115                 | Val Accuracy:  0.869                | Val F1_score: 0.787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 388/388 [01:27<00:00,  4.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 7 | Train Loss:  1.014                 | Train Accuracy:  0.916                 | Val Loss:  1.111                 | Val Accuracy:  0.876                | Val F1_score: 0.789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 388/388 [01:27<00:00,  4.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 8 | Train Loss:  0.962                 | Train Accuracy:  0.934                 | Val Loss:  1.112                 | Val Accuracy:  0.868                | Val F1_score: 0.791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ci24XFWV18OS",
        "outputId": "12e7c773-2e69-4746-f5ca-377213fe757b"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "x = ['Epoch' + str(i+1) for i in range(8)]\n",
        "\n",
        "\n",
        "plt.plot(x, val_loss_list, \"-b\", label=\"Validataion loss\")\n",
        "plt.plot(x, train_loss_list, \"-r\", label=\"Train loss\")\n",
        "\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "# plt.ylim(0, 2.0)\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mBIMVRc2W1w"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "x = ['Epoch' + str(i+1) for i in range(8)]\n",
        "\n",
        "\n",
        "plt.plot(x, train_acc_list, \"-b*\", label=\"Train accuracy\")\n",
        "plt.plot(x, val_acc_list, \"-r+\", label=\"Validataion  accuracy\")\n",
        "\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU3Jf-O32z_p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZlFHNgkhqjA",
        "outputId": "d4d10238-88d1-426a-9c6f-8f5fe0795964"
      },
      "source": [
        "\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "\n",
        "\n",
        "def evaluate(model, test_data):\n",
        "\n",
        "    test = Dataset(test_data)\n",
        "\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=835)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "        model = model.cuda()\n",
        "\n",
        "    total_acc_test = 0\n",
        "    total_f1score_test = 0 \n",
        "    counter = 0 \n",
        "    with torch.no_grad():\n",
        "\n",
        "        for test_input, test_label in test_dataloader:\n",
        "              counter +=1\n",
        "              test_label = test_label.to(device)\n",
        "              mask = test_input['attention_mask'].to(device)\n",
        "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "              output = model(input_id, mask)\n",
        "              # print(total_f1score_test,len(test_data))\n",
        "              total_f1score_test += f1_score(test_label.tolist(), output.argmax(dim=1).tolist(), average='macro')\n",
        "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
        "              total_acc_test += acc\n",
        "\n",
        "              all_meausure = []\n",
        "\n",
        "              for i in range(3):\n",
        "                temp = list(precision_recall_fscore_support(test_label.tolist(), output.argmax(dim=1).tolist(), average=None,labels=[0,1]))[i]\n",
        "                all_meausure.append(temp[0])\n",
        "                all_meausure.append(temp[1])\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
        "    print(\"f1 score:\",round(total_f1score_test/counter, 2))\n",
        "\n",
        "    return total_acc_test / len(test_data),round(total_f1score_test/counter, 2),all_meausure[0],all_meausure[1],all_meausure[2],all_meausure[3],all_meausure[4],all_meausure[5]\n",
        "Test_Accuracy,f1_macro,prec_simple,prec_hate,recall_simple,racall_hate,f1_simple,f1_hate=evaluate(model, test)\n",
        "\n",
        "\n",
        "\n",
        "Test_Accuracy,f1_macro,prec_simple,prec_hate,recall_simple,racall_hate,f1_simple,f1_hate"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:  0.879\n",
            "f1 score: 0.87\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8790419161676647,\n",
              " 0.87,\n",
              " 0.9020332717190388,\n",
              " 0.8367346938775511,\n",
              " 0.9104477611940298,\n",
              " 0.822742474916388,\n",
              " 0.9062209842154131,\n",
              " 0.8296795952782462)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "k6JcciFYa27h",
        "outputId": "0f5c3024-436a-46f5-f868-a6a79aedb01b"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "  \n",
        "# creating the dataset\n",
        "\n",
        "  \n",
        "fig = plt.figure(figsize = (10, 5))\n",
        " \n",
        "# creating the bar plot\n",
        "plt.bar(['F1_simple','F1_Hate','F1_Macro'], [f1_simple,f1_hate,f1_macro], color ='maroon',width = 0.4)\n",
        " \n",
        "plt.xlabel(\"Measure\")\n",
        "plt.ylabel(\"Percent\")\n",
        "plt.title(\"WD\")\n",
        "# plt.ylim(0, 2.0)\n",
        "plt.show()"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}